{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from modules.FastDiff.module.FastDiff_model import FastDiff\n",
    "from utils import audio\n",
    "from modules.FastDiff.module.util import compute_hyperparams_given_schedule, sampling_given_noise_schedule\n",
    "import numpy as np\n",
    "\n",
    "HOP_SIZE = 256  # for 22050 frequency\n",
    "\n",
    "# download checkpoint to this folder\n",
    "state_dict = torch.load(\"./checkpoints/FastDiff_tacotron/model_ckpt_steps_500000.ckpt\")[\"state_dict\"][\"model\"]\n",
    "\n",
    "model = FastDiff().cuda()\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "train_noise_schedule = noise_schedule = torch.linspace(1e-06, 0.01, 1000)\n",
    "diffusion_hyperparams = compute_hyperparams_given_schedule(noise_schedule)\n",
    "\n",
    "# map diffusion hyperparameters to gpu\n",
    "for key in diffusion_hyperparams:\n",
    "    if key in [\"beta\", \"alpha\", \"sigma\"]:\n",
    "        diffusion_hyperparams[key] = diffusion_hyperparams[key].cuda()\n",
    "diffusion_hyperparams = diffusion_hyperparams\n",
    "\n",
    "# load noise schedule for 8 sampling steps\n",
    "#noise_schedule = torch.FloatTensor([6.689325005027058e-07, 1.0033881153503899e-05, 0.00015496854030061513, 0.002387222135439515, 0.035597629845142365, 0.3681158423423767, 0.4735414385795593, 0.5]).cuda()\n",
    "# load noise schedule for 4 sampling steps\n",
    "noise_schedule = torch.FloatTensor([3.2176e-04, 2.5743e-03, 2.5376e-02, 7.0414e-01]).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Text-to-speech\n",
    "tacotron2 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tacotron2', model_math='fp16')\n",
    "tacotron2 = tacotron2.to(\"cuda\").eval()\n",
    "\n",
    "text = \"Welcome to a conditional diffusion probabilistic model capable of generating high fidelity speech efficiently.\"\n",
    "utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tts_utils')\n",
    "sequences, lengths = utils.prepare_input_sequence([text])\n",
    "\n",
    "with torch.no_grad():\n",
    "    mels, _, _ = tacotron2.infer(sequences, lengths)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Speech-to-waveform\n",
    "\n",
    "audio_length = mels.shape[-1] * HOP_SIZE\n",
    "pred_wav = sampling_given_noise_schedule(\n",
    "    model, (1, 1, audio_length), diffusion_hyperparams, noise_schedule,\n",
    "    condition=mels, ddim=False, return_sequence=False)\n",
    "\n",
    "pred_wav = pred_wav / pred_wav.abs().max()\n",
    "audio.save_wav(pred_wav.view(-1).cpu().float().numpy(), './test.wav', 22050)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}